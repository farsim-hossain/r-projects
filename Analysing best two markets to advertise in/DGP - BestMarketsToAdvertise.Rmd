---
title: "Finding The Best Markets To Advertise In"
output: html_notebook
---

We are an e - learning company and we want to promote our products (our courses) to market. 

The goal of this project is to find the best markets to advertise our product. 

For promoting our products, we can design the survey and conduct them in different markets. Thats one way but its expensive. What if we have a less expensive option ? What if we find data online ? 

**freecodecamp** conducted a survey that is publicly available on github. We can go through that before diving in and **go crazy** . 

Lets read the csv file first

# Exploring the data

```{r}

library(readr)
fcc <- read_csv("fcc_survey.csv")
dim(fcc)
head(fcc,5)

```



ALright ! So , personally I would want to promote the products to students who are in this learning process and who have spent more time and money to learn. The effective idea would be to find locations where these kind of students get together. 

# Sorting the data according to our target

We want to focus on the students who have similar interest in products what we offer. In this case the column `JobRoleInterest`can help us identifying those people. 

Lets see what that column tells us in summary 

```{r}
library(dplyr)
fcc %>% 
  group_by(JobRoleInterest) %>%
  summarize(freq = n()*100/nrow(fcc)) %>%
  arrange(desc(freq))

```

From the first glance, it looks like more people are interested in Full stack web developement. Also, there are people who have interest in multiple programs. 

 It'd be useful to get a better picture of how many people are interested in a single subject and how many have mixed interests. Consequently, in the next code block, we'll:

- Split each string in the `JobRoleInterest` column to find the number of options for each participant.
- We'll first drop the NA values because we cannot split NA values.
- Generate a frequency table for the variable describing the number of options.

```{r}
splitted_interests <- fcc %>%
  select(JobRoleInterest) %>%
  tidyr::drop_na() %>%
  rowwise %>% #Tidyverse actually makes by default operation over columns, rowwise changes this behavior.
  mutate(opts = length(stringr::str_split(JobRoleInterest, ",")[[1]]))

splitted_interests

```

```{r}
# Frequency table for the var describing the number of options
n_of_options <- splitted_interests %>%
  ungroup() %>%  #this is needeed because we used the rowwise() function before
  group_by(opts) %>%
  summarize(freq = n()*100/nrow(splitted_interests))
n_of_options
```

# Looking for customers for our core product - webDev and mobile Dev

It turns out that only 31.65% of the participants have a clear idea about what programming niche they'd like to work in, while the vast majority of students have mixed interests. But given that we offer courses on various subjects, the fact that new coders have mixed interest might be actually good for us.

The focus of our courses is on web and mobile development, so let's find out how many respondents chose at least one of these two options. Later, we will trace their locations. 

```{r}
web_or_mobile <- stringr :: str_detect(fcc$JobRoleInterest, "Web Developer|Mobile Developer")
freq_table <- table(web_or_mobile)
freq_table <- freq_table*100/sum(freq_table)
freq_table

```

```{r}
# Graph for the frequency table above
df <- tibble::tibble(x = c("Other Subject","Web or Mobile Developpement"),
                       y = freq_table)

df

library(ggplot2)
ggplot(data = df, aes(x = x, y = y, fill = x)) +
  geom_histogram(stat = "identity")

```

## New coders locations and densities 

Now we want to look for at least a comparison of two **best** markets to advertise in. By best markets, we mean that where are most new coders, those are interested in the subjects we teach, live in. The countryLive variable shows the locations of new coders. Our first task in this case is to make a frequency table. 

```{r}
#lets cut the crap
fcc_good <- fcc %>% 
  tidyr::drop_na(JobRoleInterest)

# Frequency tables with absolute and relative frequencies
# Display the frequency tables in a more readable format

fcc_good %>% 
  group_by(CountryLive) %>% 
  summarise(`Absolute frequency` = n(),
          `Percentage` = n() * 100 /  nrow(fcc_good) ) %>%
  arrange(desc(Percentage))


```

44.69% of our potential customers are located in the US, and this definitely seems like the most interesting market. India has the second customer density, but it's just 7.55%, which is not too far from the United Kingdom (4.50%) or Canada (3.71%).

This is useful information, but we need to go more in depth than this and figure out how much money people are actually willing to spend on learning. Advertising in high-density markets where most people are only willing to learn for free is extremely unlikely to be profitable for us.


# Spending Money for Learning

The `MoneyForLearning` column describes in American dollars the amount of money spent by participants from the moment they started coding until the moment they completed the survey. Our company sells subscriptions at a price of \$59 per month, and for this reason we're interested in finding out how much money each student spends per month.

We'll narrow down our analysis to only four countries: the US, India, the United Kingdom, and Canada. We do this for two reasons:

* These are the countries having the highest frequency in the frequency table above, which means we have a decent amount of data for each.
* Our courses are written in English, and English is an official language in all these four countries. The more people know English, the better our chances to target the right people with our ads.

Let's start with creating a new column that describes the amount of money a student has spent per month so far. To do that, we'll need to divide the `MoneyForLearning` column to the `MonthsProgramming` column. The problem is that some students answered that they have been learning to code for 0 months (it might be that they have just started). To avoid dividing by 0, we'll replace 0 with 1 in the `MonthsProgramming` column.


```{r}
# Replace 0s with 1s to avoid division by 0
fcc_good <- fcc_good %>%
  mutate(MonthsProgramming = replace(MonthsProgramming,  MonthsProgramming == 0, 1) )

# New column for the amount of money each student spends each month
fcc_good <- fcc_good %>%
  mutate(money_per_month = MoneyForLearning/MonthsProgramming) 
#total NAs
fcc_good %>%
  summarise(na_count = sum(is.na(money_per_month)) ) %>%
  pull(na_count)
```

Let's keep only the rows that don't have NA values for the `money_per_month` column.

```{r}
# Keep only the rows with non-NAs in the `money_per_month` column 
fcc_good  <-  fcc_good %>% tidyr::drop_na(money_per_month)


```

So, we have the dataset which have those students only, who spend money 

We want to group the data by country, and then measure the average amount of money that students spend per month in each country. First, let's remove the rows having `NA` values for the `CountryLive` column, and check out if we still have enough data for the four countries that interest us.

```{r}
# Remove the rows with NA values in 'CountryLive'
fcc_good  <-  fcc_good %>% tidyr::drop_na(CountryLive)
# Frequency table to check if we still have enough data
fcc_good %>% group_by(CountryLive) %>%
  summarise(freq = n() ) %>%
  arrange(desc(freq)) %>%
  head()
```


These are the real deal .

This should be enough, so let's compute the average value spent per month in each country by a student. We'll compute the average using the mean.

```{r}
# Mean sum of money spent by students each month
countries_mean  <-  fcc_good %>% 
  filter(CountryLive == 'United States of America' | CountryLive == 'India' | CountryLive == 'United Kingdom'|CountryLive == 'Canada') %>%
  group_by(CountryLive) %>%
  summarize(mean = mean(money_per_month)) %>%
  arrange(desc(mean))
countries_mean
```
On average, most money spent on e learning is by USA students. Comparing the GDP per capita, UK and Canada should be on top of India but yes, world sometimes go very unpredictable. Indian students, despite having a low income than other two countries, spend more money than UK and Canadian students.

## Dealing with extreme outliers 

It might be that we don't have have enough representative data for the United Kingdom, Canada, and India, or we have some outliers (maybe coming from wrong survey answers) making the mean too big for India, or too low for the UK and Canada. Or it might be that the results are correct.

Lets make box plots to get the insight. This is important because, outliers can affect the mean big time which wouldnt be the true representation of the scenario. For this reason, we will cut out the outliers(who spent more money in for example India, where most students spent much less than the outliers)

```{r}
# Isolate only the countries of interest
only_4  <-  fcc_good %>% 
  filter(CountryLive == 'United States of America' | CountryLive == 'India' | CountryLive == 'United Kingdom'|CountryLive == 'Canada')
# Since maybe, we will remove elements from the database, 
# we add an index column containing the number of each row. 
# Hence, we will have a match with the original database in case of some indexes.
only_4 <- only_4 %>%
  mutate(index = row_number())
# Box plots to visualize distributions
ggplot( data = only_4, aes(x = CountryLive, y = money_per_month)) +
  geom_boxplot() +
  ggtitle("Money Spent Per Month Per Country\n(Distributions)") +
  xlab("Country") +
  ylab("Money per month (US dollars)") +
  theme_bw()

```

**AAAAA ??? ** What just happened ? We see outliers from USA ! Lets cut the outliers (any value above 20000) and analyse this again. 

```{r}
fcc_good <- fcc_good %>% 
  filter(money_per_month < 20000)

countries_mean = fcc_good %>% 
  filter(CountryLive == 'United States of America' | CountryLive == 'India' | CountryLive == 'United Kingdom'|CountryLive == 'Canada') %>%
  group_by(CountryLive) %>%
  summarize(mean = mean(money_per_month)) %>%
  arrange(desc(mean))
countries_mean

```

We want to deal with only four countries. Lets make the dataset with only four countries. 

```{r}
only_4  <-  fcc_good %>% 
  filter(CountryLive == 'United States of America' | CountryLive == 'India' | CountryLive == 'United Kingdom'|CountryLive == 'Canada') %>%
  mutate(index = row_number())
# Box plots to visualize distributions
ggplot( data = only_4, aes(x = CountryLive, y = money_per_month)) +
  geom_boxplot() +
  ggtitle("Money Spent Per Month Per Country\n(Distributions)") +
  xlab("Country") +
  ylab("Money per month (US dollars)") +
  theme_bw()
```


Now its easy to detect the outliers in India. 

We can see a few extreme outliers for India (values over \$2,500 per month), but it's unclear whether this is good data or not. Maybe these persons attended several bootcamps, which tend to be very expensive. Let's examine these two data points to see if we can find anything relevant.

```{r}
# Inspect the extreme outliers for India
india_outliers  <-  only_4 %>%
  filter(CountryLive == 'India' & 
           money_per_month >= 2500)
india_outliers
```


It seems that neither participant attended a bootcamp. Overall, it's really hard to figure out from the data whether these persons really spent that much money with learning. The actual question of the survey was _"Aside from university tuition, about how much money have you spent on learning to code so far (in US dollars)?"_, so they might have misunderstood and thought university tuition is included. It seems safer to remove these six rows.

```{r}
# Remove the outliers for India
# Indexing is always useful
only_4 <-  only_4 %>% 
  filter(!(index %in% india_outliers$index))
```


Looking back at the box plot above, we can also see more extreme outliers for the US (values over \$6,000 per month). Let's examine these participants in more detail.

```{r}
# Examine the extreme outliers for the US
us_outliers = only_4 %>%
  filter(CountryLive == 'United States of America' & 
           money_per_month >= 6000)
us_outliers
only_4  <-  only_4 %>% 
  filter(!(index %in% us_outliers$index))
```

These are the outliers in USA. 6 of them attended bootcamps and probably they paid in advance for the bootcamps that large amount of money. That is justified, but there are people who didnt attend bootcamps but spent more than 6k. We will remove these outliers. Also, the data shows that eight respondents had been programming for no more than three months when they completed the survey. They most likely paid a large sum of money for a bootcamp that was going to last for several months, so the amount of money spent per month is unrealistic and should be significantly lower (because they probably didn't spend anything for the next couple of months after the survey). As a consequence, we'll remove every these eight outliers too. 

```{r}
# extract the people we dont want in our analysis 

no_bootcamp <- only_4 %>% 
  filter(CountryLive == 'United States of America' & money_per_month >= 6000 & AttendedBootcamp == 0)

only_4  <-  only_4 %>% 
  filter(!(index %in% no_bootcamp$index))

# Remove the respondents that had been programming for less than 3 months
less_than_3_months = only_4 %>%
    filter(CountryLive == 'United States of America' & 
           money_per_month >= 6000 &
           MonthsProgramming <= 3)
only_4  <-  only_4 %>% 
  filter(!(index %in% less_than_3_months$index))
```
  
Looking again at the last box plot above, we can also see an extreme outlier for Canada — a person who spends roughly \$5,000 per month. Let's examine this person in more depth.

```{r}
# Examine the extreme outliers for Canada
canada_outliers = only_4 %>%
  filter(CountryLive == 'Canada' & 
           money_per_month >= 4500 &
           MonthsProgramming <= 3)
canada_outliers
```

Here, the situation is similar to some of the US respondents — this participant had been programming for no more than two months when he completed the survey. He seems to have paid a large sum of money in the beginning to enroll in a bootcamp, and then he probably didn't spend anything for the next couple of months after the survey. We'll take the same approach here as for the US and remove this outlier.


```{r}
# Remove the extreme outliers for Canada
only_4  <-  only_4 %>% 
  filter(!(index %in% canada_outliers$index))
```

Let's recompute the mean values and generate the final box plots.

```{r}
# Mean sum of money spent by students each month
countries_mean = only_4 %>%
  group_by(CountryLive) %>%
  summarize(mean = mean(money_per_month)) %>%
  arrange(desc(mean))
countries_mean
```

**Now, after removing the outliers, we see that Indian students literally paid less than Canadians on average.** 

```{r}
# Box plots to visualize distributions
ggplot( data = only_4, aes(x = CountryLive, y = money_per_month)) +
  geom_boxplot() +
  ggtitle("Money Spent Per Month Per Country\n(Distributions)") +
  xlab("Country") +
  ylab("Money per month (US dollars)") +
  theme_bw()
```

## Choosing the best two markets 

Our subscription price is $59. Clearly, USA will be the first choice to advertise in. 
The analysis upto this point, suggests that Canada should be the second choice.

but let's take a second look at India before deciding to choose Canada as our second best choice:

**But did we consider the number of potential customers in India vs UK? ** 

$59 USD is still approachable to India as their AVG spending is 66 USD.

```{r}
# Frequency table for the 'CountryLive' column
only_4 %>% group_by(CountryLive) %>%
  summarise(freq = n() * 100 / nrow(only_4) ) %>%
  arrange(desc(freq)) %>%
  head()
```

```{r}
# Frequency table to check if we still have enough data
only_4 %>% group_by(CountryLive) %>%
  summarise(freq = n() ) %>%
  arrange(desc(freq)) %>%
  head()
```


So it's not crystal clear what to choose between Canada and India. Although it seems more tempting to choose Canada, there are good chances that India might actually be a better choice because of the large number of potential customers.

At this point, it seems that we have several options:

1. Advertise in the US, India, and Canada by splitting the advertisement budget in various combinations:
    - 60% for the US, 25% for India, 15% for Canada.
    - 50% for the US, 30% for India, 20% for Canada; etc.

2. Advertise only in the US and India, or the US and Canada. Again, it makes sense to split the advertisement budget unequally. For instance:
    - 70% for the US, and 30% for India.
    - 65% for the US, and 35% for Canada; etc.

3. Advertise only in the US.

At this point, it's probably best to send our analysis to the marketing team and let them use their domain knowledge to decide. They might want to do some extra surveys in India and Canada and then get back to us for analyzing the new survey data.

# Conclusion

In this project, we analyzed survey data from new coders to find the best two markets to advertise in. The only solid conclusion we reached is that the US would be a good market to advertise in.

For the second best market, it wasn't clear-cut what to choose between India and Canada. We decided to send the results to the marketing team so they can use their domain knowledge to take the best decision.

