---
title: "Fundango Movie Ratings : Do they still overrate movies ?"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract 

In October 2015, a data journalist named Walt Hickey analyzed movie ratings data and found strong evidence to suggest that Fandango's rating system was biased and dishonest. The actual rating was almost always rounded up to the nearest half-star. For instance, a 4.1 movie would be rounded off to 4.5 stars, not to 4 stars, as you may expect.

In this project, we'll analyze more recent movie ratings data to determine whether there has been any change in Fandango's rating system after Hickey's analysis.


We have two csv files which represents the data collected by Hicky - means they were collected before his analysis and another csv file that shows the data after his analysis . 

Lets import them 

```{r}
library(readr)
previous <- read_csv('fandango_score_comparison.csv')
after <- read_csv('movie_ratings_16_17.csv')

```

Check check ..

```{r}
head(previous)
```

```{r}
head(after)
```

Below we isolate only the columns that provide information about Fandango so we make the relevant data more readily available for later use. 

```{r message=FALSE}
library(dplyr)
fandango_previous <- previous %>% 
  select(FILM, Fandango_Stars, Fandango_Ratingvalue, 
         Fandango_votes, Fandango_Difference)
fandango_after <- after %>% 
  select(movie, year, fandango)
head(fandango_previous)
```

```{r}
head(fandango_after)
```
We want to describe the population, so we need to make sure that the samples are representative, otherwise we should expect a large sampling error and, ultimately, wrong conclusions.

From Hickey's article and from the README.md of [the data set's repository](https://github.com/fivethirtyeight/data/tree/master/fandango), we can see that he used the following sampling criteria:

* The movie must have had at least 30 fan ratings on Fandango's website at the time of sampling (Aug. 24, 2015).
* The movie must have had tickets on sale in 2015.

The sampling was clearly not random because not every movie had the same chance to be included in the sample — some movies didn't have a chance at all (like those having under 30 fan ratings or those without tickets on sale in 2015). It's questionable whether this sample is representative of the entire population we're interested to describe. It seems more likely that it isn't, mostly because this sample is subject to temporal trends — e.g. movies in 2015 might have been outstandingly good or bad compared to other years.

The sampling conditions for our other sample were (as it can be read in the README.md of [the data set's repository](https://github.com/mircealex/Movie_ratings_2016_17)):

* The movie must have been released in 2016 or later.
* The movie must have had a considerable number of votes and reviews (unclear how many from the README.md or from the data).
This second sample is also subject to temporal trends and it's unlikely to be representative of our population of interest.


## Now what 

Both of these data collectors had their different research objectives which led them to set indivdual criteria for their samples. Their samples dont represent the same categories to compare a movie. That means it wont serve our purpose to clearly compare two situations. 

At this point, we have at least two alternatives: either we collect new data, either we change the goal of our analysis by placing some limitations on it.

Tweaking our goal seems a much faster choice compared to collecting new data. Also, it's quasi-impossible to collect a new sample previous to Hickey's analysis at this moment in time.

## Change slightly the current goal of our analysis

At this point, we can either collect new data or change our the goal of our analysis. We choose the latter and place some limitations on our initial goal.

Instead of trying to determine whether there has been any change in Fandango's rating system after Hickey's analysis, our new goal is to determine whether there's any difference between **Fandango's ratings for popular movies in 2015 and Fandango's ratings for popular movies in 2016.** This new goal should also be a fairly good proxy for our initial goal.

## Islolating the samples we need 

we have two populations of interest:

1. All Fandango's ratings for popular movies released in 2015.
1. All Fandango's ratings for popular movies released in 2016.

**we need to be clear about what counts as popuar movies.** We'll use Hickey's benchmark of 30 fan ratings and count a movie as popular only if it has 30 fan ratings or more on Fandango's website.

Theres a problem. One of our new datasets "fundango_after" doesnt have a column which shows the number of ratings. One quick way to check the representativity of this sample might be to sample randomly 10 movies from it and then check the number of fan ratings ourselves on Fandango's website. 

```{r}
set.seed(1)
sample_n(fandango_after, size = 10)
```

So we went to Fandango, as part of this investigation process, we have to explore. Fandango dont uses a 5 star rating anymore from 2019. 

Instead, Fandango now uses the [Rotten Tomatoes verified Audience Score](https://editorial.rottentomatoes.com/article/introducing-verified-audience-score/).

**We are still trying to find an optimized and acceptable foundation on which the 2015 and 2016 movies can be judged.**

Now lets check how many audience have rated those 10 movies. We have visited fandango first, there were no numbers of ratings(we wanted to see whether these 10 movies have minimum 30 ratings or not) and then we were directed to **rottentomatoes**. When we dig in the details, we found the ratings in thousands !. 

We will make a new column called reviews, which will be filled up by the number of reviews found on rotten tomatoes. 

```{r}
set.seed(1)
sampled <- sample_n(fandango_after, size = 10)
# Create a single column tibble of Rotten Tomato review counts
reviews <- tibble(reviews = c(13569, 74904, 24293, 4141, 30183, 48952, 14328, 59359, 54765, 82222))
bind_cols(sampled, reviews)
```

## Lets call our reseach question again 

We want to find out the difference between fandango's "popular movies" in 2015 vs 2016. We want to see how do they rate the popular movies in 2016 comparing to 2015. 

## coming back from the last code 

All ten movies sampled have well above 30 fan ratings, but it is possible that the Rotten Tomatoes Verified Audience user base is larger than the Fandango user base.(means rotten tomatto could easily have more than 30 reviews if they have more audience) We cannot really say with confidence whether these review numbers are comparable to the Fandango fan ratings. 

In addition, time has passed since Hickey's analysis, giving more fans an opportunity to submit reviews. So even if we did still have access to Fandango's 5-star fan ratings, we would have no way to compare the number of fan ratings we see to the number that Hickey observed. 

Let's move on to the `fandango_previous` dataframe that does include the number of fan ratings for each movie. The "readme" documentation states clearly that there're only movies with at least 30 fan ratings.


```{r}
sum(fandango_previous$Fandango_votes < 30)
```
So there were not a single movie in our dataset that Mr. Hicky analyzed, which had less than 30 reviews. 


If we explore the two data sets, we'll notice that there are movies with a releasing year different(even 2014) than 2015 or 2016. 

```{r}
head(fandango_previous$FILM, n = 10)
```


```{r}
unique(fandango_after$year)
```

So we will isolate the movies those were released only in 2015 and 2016. We will use str_sub to extract the year only.

```{r}
library(stringr)
fandango_previous <- fandango_previous %>% 
  mutate(year = str_sub(FILM, -5, -2))
```

Let's examine the frequency distribution for the Year column and then isolate the movies released in 2015.

```{r}
fandango_previous %>% 
  group_by(year) %>% 
  summarize(Freq = n())
```

## Extracting only 2015 and 2016 movies from the datasets. 

```{r}
fandango_2015 <- fandango_previous %>% 
                        filter(year == 2015)
#check 
table(fandango_2015$year)
```

Lets islolate 2016 movies 

```{r}
table(fandango_after$year)
```
```{r}
fandango_2016 <- fandango_after %>%
                      filter(year == 2016)
#check 
table(fandango_2016$year)


```

## Here comes the analysis part 


lets visualize the data. BY visualizing , we should find something regarding movie ratings. Our concerned variables for 2015 = fandango_stars, for 2016 = fandango. 

We'll start with comparing the shape of the two distributions using kernel density plots.

```{r}
library(ggplot2)
# 2015 dataframe is specified in the ggplot call
ggplot(data = fandango_2015, 
               aes(x = Fandango_Stars)) +
  geom_density() +
  # 2016 dataframe is specified in the second geom_density() call
  geom_density(data = fandango_2016, 
               aes(x = fandango), color = "blue") +
  
  labs(title = "Comparing distribution shapes for Fandango's ratings\n(2015 vs 2016)",
       x = "Stars",
       y = "Density") +
  scale_x_continuous(breaks = seq(0, 5, by = 0.5), 
                     limits = c(0, 5))
```

* Both distributions are strongly left skewed.
* The 2016 distribution is slightly shifted to the left relative to the 2015 distribution.



The left skew suggests that movies on Fandango are given mostly high and very high fan ratings.

The slight left shift of the 2016 distribution is very interesting for our analysis. It shows that ratings were slightly lower in 2016 compared to 2015. This suggests that there was a difference indeed between Fandango's ratings for popular movies in 2015 and Fandango's ratings for popular movies in 2016. We can also see the direction of the difference: the ratings in 2016 were slightly lower compared to 2015.


## Relative frequencies of two distributions 

```{r}
fandango_2015 %>%
    group_by(Fandango_Stars) %>%
        summarize(Percentage = n()/nrow(fandango_2015)*100)
```

```{r}
fandango_2016 %>%
    group_by(fandango) %>%
        summarize(Percentage = n()/nrow(fandango_2016)*100)
```


In 2016, very high ratings (4.5 and 5 stars) had lower percentages compared to 2015. In 2016, under 1% of the movies had a perfect rating of 5 stars, compared to 2015 when the percentage was close to 7%. Ratings of 4.5 were also more popular in 2015 — there were approximately 13% more movies rated with a 4.5 in 2015 compared to 2016.

The minimum rating is also lower in 2016 — 2.5 instead of 3 stars, the minimum of 2015. There clearly is a difference between the two frequency distributions.

For some other ratings, the percentage went up in 2016. There was a greater percentage of movies in 2016 that received 3.5 and 4 stars, compared to 2015. 3.5 and 4.0 are high ratings and this challenges the direction of the change we saw on the kernel density plots.


```{r}
fandango_2015
```

```{r}
fandango_2016
```

## Determining the direction of change 

We'll take a couple of summary statistics to get a more precise picture about the direction of the difference. We'll take each distribution of movie ratings and compute its mean, median, and mode, and then compare these statistics to determine what they tell about the direction of the difference.

**Compute the mean, median, and mode for each distribution.**

baseR dont have the mode function. We have to make one. This one we got from stackoverflow


```{r}
library(tidyr)

mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

summary_2015 <- fandango_2015 %>%
  summarize(year = "2015",
            mean = mean(Fandango_Stars),
            median = median(Fandango_Stars),
            mode = mode(Fandango_Stars))
summary_2016 <- fandango_2016 %>%
  summarize(year = "2016",
            mean = mean(fandango),
            median = median(fandango),
            mode = mode(fandango))

# Combine 2015 & 2016 summary dataframes
summary_df <- bind_rows(summary_2015, summary_2016)

summary_df





```

Its clearly seen that in 2016, most of the movies were given 4.0 comparing to the previous year (4.5). The mean rating has also decreased. 

We want to visualize the thing

```{r}
# organizing the dataframe for ggplot
summary_df <- summary_df %>% 
  gather(key = "statistic", value = "value", - year)
summary_df

```

```{r}
ggplot(data = summary_df, aes(x = statistic, y = value, fill = year)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Comparing summary statistics: 2015 vs 2016",
       x = "",
       y = "Stars")
```
The mean rating was lower in 2016 with approximately 0.2. 

```{r}
means <- summary_df %>% 
  filter(statistic == "mean")
means %>% 
  summarize(change = (value[1] - value[2]) / value[1])

means
```

**This means a drop of almost 5% relative to the mean rating in 2015.**

## Conclusion

Our analysis showed that there's indeed a slight difference between Fandango's ratings for popular movies in 2015 and Fandango's ratings for popular movies in 2016. We also determined that, on average, popular movies released in 2016 were rated lower on Fandango than popular movies released in 2015.

We cannot be completely sure what caused the change, but the chances are very high that it was caused by Fandango fixing the biased rating system after Hickey's analysis.












